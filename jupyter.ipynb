{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The author of paper propose a simple and effective end-to-end image segmentation network architecture for medical images.\n",
    "The proposed network, called U-net, has main three factors for well-training.\n",
    "- U-shaped network structure with two configurations: Contracting and Expanding path\n",
    "- Training more faster than sliding-windows: Patch units and Overlap-tile\n",
    "- Data augmentation: Elastic deformation and Weight cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we used is Transmission Electron Microscopy (ssTEM) data set of the Drosophila first instar larva ventral nerve cord (VNC), which is dowloaded from [ISBI Challenge: Segmentation of of neural structures in EM stacks](http://brainiac2.mit.edu/isbi_challenge/home)\n",
    "\n",
    "\n",
    "![ISBI](./images/ISBI.gif)\n",
    "\n",
    "\n",
    "- Black and white segmentation of membrane and cell with EM(Electron Microscopic) image.\n",
    "- The data set is a large size of image and few so the data augmentation is needed.\n",
    "- The data set contains 30 images of size 512x512 for the train, train-labels and test.\n",
    "- There is no images for test-labels for the ISBI competition.\n",
    "- If you want to get the evaluation metrics of competition, you should split part of the train data set for testing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlap-tile\n",
    "\n",
    "\n",
    "#### Sliding Window\n",
    "![sliding_window](./images/sliding_window.png) \n",
    "\n",
    "\n",
    "#### Patch\n",
    "![patch](./images/patch.png) \n",
    "\n",
    "\n",
    "- Patch method has low overlap ratio so that the speed of detection can be improvement.\n",
    "- However, as the wide size of patch detect image at once, the performance of context is good but the performance of localization is lower.\n",
    "- In this paper, the U-net architecture and overlap-tile methods were proposed to solve this localization problem.\n",
    "\n",
    "\n",
    "#### Overlap-tile\n",
    "![overlap_tile](./images/overlap_tile.png)\n",
    "\n",
    "\n",
    "Simple. Because the EM image is large, sometimes the model of detection input is larger than the patch size (yellow). If so, mirror and fill in the patch area with the empty part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmenation\n",
    "\n",
    "We preprocessed the images for data augmentation. Following preprocessing are :\n",
    "   * Flip\n",
    "   * Gaussian noise\n",
    "   * Uniform noise\n",
    "   * Brightness\n",
    "   * Elastic deformation\n",
    "   * Crop\n",
    "   * Pad \n",
    "   \n",
    "You can easily to understand refer this [page](https://github.com/ugent-korea/pytorch-unet-segmentation/blob/master/README.md#preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image, ImageSequence\n",
    "import os\n",
    "\n",
    "\n",
    "class dataProcess(object):\n",
    "    def __init__(self, out_rows, out_cols, data_path=\"./data\"):\n",
    "        self.out_rows = out_rows\n",
    "        self.out_cols = out_cols\n",
    "        self.data_path = data_path\n",
    "\n",
    "    def create_train_data(self):\n",
    "        print('-' * 30)\n",
    "        print('Creating train images...')\n",
    "        print('-' * 30)\n",
    "\n",
    "        # Load images and convert to npy\n",
    "        i = 0\n",
    "        j = 0\n",
    "        imgs = os.listdir(self.data_path + \"/raw/images/\")\n",
    "        aug_imgs = os.listdir(self.data_path + \"/aug/images/\")\n",
    "        print(\"original images\", len(imgs))\n",
    "        print(\"augmented images\", len(aug_imgs))\n",
    "        img_datas = np.ndarray((len(imgs) + len(aug_imgs), self.out_rows, self.out_cols, 1), dtype=np.uint8)\n",
    "        img_labels = np.ndarray((len(imgs) + len(aug_imgs), self.out_rows, self.out_cols, 1), dtype=np.uint8)\n",
    "        for imgname in imgs:\n",
    "            img = load_img(self.data_path + \"/raw/images/\" + imgname, color_mode=\"grayscale\")\n",
    "            label = load_img(self.data_path + \"/raw/labels/\" + imgname, color_mode=\"grayscale\")\n",
    "            img_datas[j] = img_to_array(img)\n",
    "            img_labels[j] = img_to_array(label)\n",
    "            j += 1\n",
    "            if j % len(imgs) == 0:\n",
    "                print('Done: {0}/{1} images'.format(j, len(imgs)))\n",
    "        for imgname in aug_imgs:\n",
    "            img = load_img(self.data_path + \"/aug/images/\" + imgname, color_mode=\"grayscale\")\n",
    "            label = load_img(self.data_path + \"/aug/labels/\" + imgname, color_mode=\"grayscale\")\n",
    "            img_datas[i + len(imgs)] = img_to_array(img)\n",
    "            img_labels[i + len(imgs)] = img_to_array(label)\n",
    "            i += 1\n",
    "            if i % 100 == 0:\n",
    "                print('Done: {0}/{1} images'.format(i, len(aug_imgs)))\n",
    "\n",
    "        print('loading done')\n",
    "        np.save(self.data_path + '/npy/imgs_train.npy', img_datas)\n",
    "        np.save(self.data_path + '/npy/imgs_mask_train.npy', img_labels)\n",
    "        print('Saving to .npy files done.')\n",
    "\n",
    "    def create_test_data(self):\n",
    "        print('-' * 30)\n",
    "        print('Creating test images...')\n",
    "        print('-' * 30)\n",
    "\n",
    "        # Create directory\n",
    "        if not os.path.exists(self.data_path + \"/test/images\"):\n",
    "            os.makedirs(self.data_path + \"/test/images\")\n",
    "        if not os.path.exists(self.data_path + \"/test/labels\"):\n",
    "            os.makedirs(self.data_path + \"/test/labels\")\n",
    "\n",
    "        # Split isbi tif image&label to single frame of png images\n",
    "        isbi_img = Image.open(self.data_path + \"/test-volume.tif\")  # raw image from isbi dataset\n",
    "        for i, page in enumerate(ImageSequence.Iterator(isbi_img)):\n",
    "            page.save(self.data_path+\"/test/images/\" + str(i) + \".png\")\n",
    "\n",
    "        imgs = os.listdir(self.data_path + \"/raw/images/\")\n",
    "        imgs = sorted([str(i).rstrip('.png') for i in imgs], key=int) # sort accending\n",
    "        img_datas = np.ndarray((len(imgs), self.out_rows, self.out_cols, 1), dtype=np.uint8)\n",
    "        i = 0\n",
    "        for imgname in imgs:\n",
    "            img = load_img(self.data_path + \"/test/images/\" + imgname + \".png\", color_mode=\"grayscale\")\n",
    "            img_datas[i] = img_to_array(img)\n",
    "            i += 1\n",
    "            if i % len(imgs) == 0:\n",
    "                print('Done: {0}/{1} images'.format(i, len(imgs)))\n",
    "        print('loading done')\n",
    "        np.save(self.data_path + '/npy/imgs_test.npy', img_datas)\n",
    "        print('Saving to .npy files done.')\n",
    "\n",
    "    def load_train_data(self):\n",
    "        print('-' * 30)\n",
    "        print('load train images...')\n",
    "        print('-' * 30)\n",
    "        imgs_train = np.load(self.data_path + \"/npy/imgs_train.npy\")\n",
    "        imgs_mask_train = np.load(self.data_path + \"/npy/imgs_mask_train.npy\")\n",
    "        imgs_train = imgs_train.astype('float32')\n",
    "        imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "        imgs_train /= 255  # RGB 0~1\n",
    "        imgs_mask_train /= 255\n",
    "        imgs_mask_train[imgs_mask_train > 0.5] = 1\n",
    "        imgs_mask_train[imgs_mask_train <= 0.5] = 0\n",
    "        return imgs_train, imgs_mask_train\n",
    "\n",
    "    def load_test_data(self):\n",
    "        print('-' * 30)\n",
    "        print('load test images...')\n",
    "        print('-' * 30)\n",
    "        imgs_test = np.load(self.data_path + \"/npy/imgs_test.npy\")\n",
    "        imgs_test = imgs_test.astype('float32')\n",
    "        imgs_test /= 255\n",
    "        return imgs_test\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mydata = dataProcess(512, 512)\n",
    "    mydata.create_train_data()\n",
    "    mydata.create_test_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data pre-process for converting .tif to .png\n",
    "\n",
    "Create the train, train-label, test png image files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image, ImageSequence\n",
    "import os\n",
    "\n",
    "\n",
    "class dataProcess(object):\n",
    "    def __init__(self, out_rows, out_cols, data_path=\"./data\"):\n",
    "        self.out_rows = out_rows\n",
    "        self.out_cols = out_cols\n",
    "        self.data_path = data_path\n",
    "\n",
    "    def create_train_data(self):\n",
    "        print('-' * 30)\n",
    "        print('Creating train images...')\n",
    "        print('-' * 30)\n",
    "\n",
    "        # Load images and convert to npy\n",
    "        i = 0\n",
    "        j = 0\n",
    "        imgs = os.listdir(self.data_path + \"/raw/images/\")\n",
    "        aug_imgs = os.listdir(self.data_path + \"/aug/images/\")\n",
    "        print(\"original images\", len(imgs))\n",
    "        print(\"augmented images\", len(aug_imgs))\n",
    "        img_datas = np.ndarray((len(imgs) + len(aug_imgs), self.out_rows, self.out_cols, 1), dtype=np.uint8)\n",
    "        img_labels = np.ndarray((len(imgs) + len(aug_imgs), self.out_rows, self.out_cols, 1), dtype=np.uint8)\n",
    "        for imgname in imgs:\n",
    "            img = load_img(self.data_path + \"/raw/images/\" + imgname, color_mode=\"grayscale\")\n",
    "            label = load_img(self.data_path + \"/raw/labels/\" + imgname, color_mode=\"grayscale\")\n",
    "            img_datas[j] = img_to_array(img)\n",
    "            img_labels[j] = img_to_array(label)\n",
    "            j += 1\n",
    "            if j % len(imgs) == 0:\n",
    "                print('Done: {0}/{1} images'.format(j, len(imgs)))\n",
    "        for imgname in aug_imgs:\n",
    "            img = load_img(self.data_path + \"/aug/images/\" + imgname, color_mode=\"grayscale\")\n",
    "            label = load_img(self.data_path + \"/aug/labels/\" + imgname, color_mode=\"grayscale\")\n",
    "            img_datas[i + len(imgs)] = img_to_array(img)\n",
    "            img_labels[i + len(imgs)] = img_to_array(label)\n",
    "            i += 1\n",
    "            if i % 100 == 0:\n",
    "                print('Done: {0}/{1} images'.format(i, len(aug_imgs)))\n",
    "\n",
    "        print('loading done')\n",
    "        np.save(self.data_path + '/npy/imgs_train.npy', img_datas)\n",
    "        np.save(self.data_path + '/npy/imgs_mask_train.npy', img_labels)\n",
    "        print('Saving to .npy files done.')\n",
    "\n",
    "    def create_test_data(self):\n",
    "        print('-' * 30)\n",
    "        print('Creating test images...')\n",
    "        print('-' * 30)\n",
    "\n",
    "        # Create directory\n",
    "        if not os.path.exists(self.data_path + \"/test/images\"):\n",
    "            os.makedirs(self.data_path + \"/test/images\")\n",
    "        if not os.path.exists(self.data_path + \"/test/labels\"):\n",
    "            os.makedirs(self.data_path + \"/test/labels\")\n",
    "\n",
    "        # Split isbi tif image&label to single frame of png images\n",
    "        isbi_img = Image.open(self.data_path + \"/test-volume.tif\")  # raw image from isbi dataset\n",
    "        for i, page in enumerate(ImageSequence.Iterator(isbi_img)):\n",
    "            page.save(self.data_path+\"/test/images/\" + str(i) + \".png\")\n",
    "\n",
    "        imgs = os.listdir(self.data_path + \"/raw/images/\")\n",
    "        imgs = sorted([str(i).rstrip('.png') for i in imgs], key=int) # sort accending\n",
    "        img_datas = np.ndarray((len(imgs), self.out_rows, self.out_cols, 1), dtype=np.uint8)\n",
    "        i = 0\n",
    "        for imgname in imgs:\n",
    "            img = load_img(self.data_path + \"/test/images/\" + imgname + \".png\", color_mode=\"grayscale\")\n",
    "            img_datas[i] = img_to_array(img)\n",
    "            i += 1\n",
    "            if i % len(imgs) == 0:\n",
    "                print('Done: {0}/{1} images'.format(i, len(imgs)))\n",
    "        print('loading done')\n",
    "        np.save(self.data_path + '/npy/imgs_test.npy', img_datas)\n",
    "        print('Saving to .npy files done.')\n",
    "\n",
    "    def load_train_data(self):\n",
    "        print('-' * 30)\n",
    "        print('load train images...')\n",
    "        print('-' * 30)\n",
    "        imgs_train = np.load(self.data_path + \"/npy/imgs_train.npy\")\n",
    "        imgs_mask_train = np.load(self.data_path + \"/npy/imgs_mask_train.npy\")\n",
    "        imgs_train = imgs_train.astype('float32')\n",
    "        imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "        imgs_train /= 255  # RGB 0~1\n",
    "        imgs_mask_train /= 255\n",
    "        imgs_mask_train[imgs_mask_train > 0.5] = 1\n",
    "        imgs_mask_train[imgs_mask_train <= 0.5] = 0\n",
    "        return imgs_train, imgs_mask_train\n",
    "\n",
    "    def load_test_data(self):\n",
    "        print('-' * 30)\n",
    "        print('load test images...')\n",
    "        print('-' * 30)\n",
    "        imgs_test = np.load(self.data_path + \"/npy/imgs_test.npy\")\n",
    "        imgs_test = imgs_test.astype('float32')\n",
    "        imgs_test /= 255\n",
    "        return imgs_test\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mydata = dataProcess(512, 512)\n",
    "    mydata.create_train_data()\n",
    "    mydata.create_test_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Unet](./images/unet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contracting Path (Fully Convolution)\n",
    "- Typical convolutional network.\n",
    "- 3x3 convolution layer with max-pooling and drop out\n",
    "- Extracts the image feature accurately, but reduces the size of the image feature map.\n",
    "\n",
    "\n",
    "### Expanding Path (Deconvolution)\n",
    "- Output segmentation map by upsampling the feature map\n",
    "- 2x2 up-convolution and 3x3 convolution layer with concatenation\n",
    "- The disadvantage of upsampling process is that the localization information in the image feature map will be lost.\n",
    "- Therefore, localization information less lost by concatenating the feature map after up-conv with the same level feature map.\n",
    "- Last one is 1x1 convolution mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def unet(pretrained_weights = None,input_size = (512,512,1)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4) # for crop and copy\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3) # Concatenate for localization informantion\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    #model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "from model import unet\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tifffile import imsave as tifsave\n",
    "import tensorflow as tf\n",
    "\n",
    "# Use other GPU in our mlti-gpu server\n",
    "# If you have only one GPU, change 1 to 0 or delete below lines\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "\n",
    "\n",
    "class myUnet(object):\n",
    "\n",
    "    def __init__(self, img_rows=512, img_cols=512, save_path=\"./results/\"):\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def load_data(self):\n",
    "        mydata = dataProcess(self.img_rows, self.img_cols)\n",
    "        imgs_train, imgs_mask_train = mydata.load_train_data()\n",
    "        imgs_test = mydata.load_test_data()\n",
    "        return imgs_train, imgs_mask_train, imgs_test\n",
    "\n",
    "    def train(self, load_pretrained):\n",
    "        print(\"loading data\")\n",
    "        model_name = 'my_model.h5'\n",
    "        log_dir = \"logs/000\"\n",
    "        logging = TensorBoard(log_dir=log_dir)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
    "        imgs_train, imgs_mask_train, imgs_test = self.load_data()\n",
    "        print(\"loading data done\")\n",
    "        if load_pretrained:\n",
    "            model = load_model(model_name)\n",
    "            model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "            model_checkpoint = ModelCheckpoint('unet.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "            model.fit(imgs_train, imgs_mask_train, batch_size=4, epochs=30, verbose=1,\n",
    "                      validation_split=0.2, shuffle=True, callbacks=[logging, model_checkpoint, reduce_lr])\n",
    "            model.save(model_name)\n",
    "        else:\n",
    "            model = unet()\n",
    "            model.summary()\n",
    "            model_checkpoint = ModelCheckpoint('unet.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "            model.fit(imgs_train, imgs_mask_train, batch_size=4, epochs=30, verbose=1,\n",
    "                      validation_split=0.2, shuffle=True,\n",
    "                      callbacks=[logging, model_checkpoint, reduce_lr, early_stopping])\n",
    "            model.save(model_name)\n",
    "\n",
    "    def test(self):\n",
    "        model_name = 'my_model.h5'\n",
    "        if not os.path.exists(self.save_path):\n",
    "            os.makedirs(self.save_path)\n",
    "\n",
    "        imgs_train, imgs_mask_train, imgs_test = self.load_data()\n",
    "        model = load_model(model_name)\n",
    "        imgs_mask_test = model.predict(imgs_test, batch_size=2, verbose=1)\n",
    "        np.save(self.save_path + \"imgs_mask_test.npy\", imgs_mask_test)\n",
    "\n",
    "        print(\"array to image\")\n",
    "        imgs = np.load(self.save_path + \"imgs_mask_test.npy\")\n",
    "        total = []\n",
    "        for i in range(imgs.shape[0]):\n",
    "            img = imgs[i]\n",
    "            img[img > 0.5] = 1\n",
    "            img[img <= 0.5] = 0\n",
    "            total.append(img)\n",
    "        np_total = np.array(total)\n",
    "        tifsave(\"./prediction.tif\", np_total)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if gpus:\n",
    "        try:\n",
    "            myunet = myUnet()\n",
    "            myunet.train(load_pretrained=False)\n",
    "            myunet.test()\n",
    "        except RuntimeError as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "![result](./images/result.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from random import randint\n",
    "\n",
    "\n",
    "def add_elastic_transform(image, alpha, sigma, pad_size=30, seed=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image : numpy array of image\n",
    "        alpha : α is a scaling factor\n",
    "        sigma :  σ is an elasticity coefficient\n",
    "        random_state = random integer\n",
    "        Return :\n",
    "        image : elastically transformed numpy array of image\n",
    "    \"\"\"\n",
    "    image_size = int(image.shape[0])\n",
    "    image = np.pad(image, pad_size, mode=\"symmetric\")\n",
    "    if seed is None:\n",
    "        seed = randint(1, 100)\n",
    "        random_state = np.random.RandomState(seed)\n",
    "    else:\n",
    "        random_state = np.random.RandomState(seed)\n",
    "    shape = image.shape\n",
    "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1),\n",
    "                         sigma, mode=\"constant\", cval=0) * alpha\n",
    "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1),\n",
    "                         sigma, mode=\"constant\", cval=0) * alpha\n",
    "    x, y = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]))\n",
    "    indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1))\n",
    "    return cropping(map_coordinates(image, indices, order=1).reshape(shape), 512, pad_size, pad_size), seed\n",
    "\n",
    "\n",
    "def flip(image, option_value):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image : numpy array of image\n",
    "        option_value = random integer between 0 to 3\n",
    "    Return :\n",
    "        image : numpy array of flipped image\n",
    "    \"\"\"\n",
    "    if option_value == 0:\n",
    "        # vertical\n",
    "        image = np.flip(image, option_value)\n",
    "    elif option_value == 1:\n",
    "        # horizontal\n",
    "        image = np.flip(image, option_value)\n",
    "    elif option_value == 2:\n",
    "        # horizontally and vertically flip\n",
    "        image = np.flip(image, 0)\n",
    "        image = np.flip(image, 1)\n",
    "    else:\n",
    "        image = image\n",
    "        # no effect\n",
    "    return image\n",
    "\n",
    "\n",
    "def add_gaussian_noise(image, mean=0, std=1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image : numpy array of image\n",
    "        mean : pixel mean of image\n",
    "        standard deviation : pixel standard deviation of image\n",
    "    Return :\n",
    "        image : numpy array of image with gaussian noise added\n",
    "    \"\"\"\n",
    "    gaus_noise = np.random.normal(mean, std, image.shape)\n",
    "    image = image.astype(\"int16\")\n",
    "    noise_img = image + gaus_noise\n",
    "    image = ceil_floor_image(image)\n",
    "    return noise_img\n",
    "\n",
    "\n",
    "def add_uniform_noise(image, low=-10, high=10):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image : numpy array of image\n",
    "        low : lower boundary of output interval\n",
    "        high : upper boundary of output interval\n",
    "    Return :\n",
    "        image : numpy array of image with uniform noise added\n",
    "    \"\"\"\n",
    "    uni_noise = np.random.uniform(low, high, image.shape)\n",
    "    image = image.astype(\"int16\")\n",
    "    noise_img = image + uni_noise\n",
    "    image = ceil_floor_image(image)\n",
    "    return noise_img\n",
    "\n",
    "\n",
    "def change_brightness(image, value):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image : numpy array of image\n",
    "        value : brightness\n",
    "    Return :\n",
    "        image : numpy array of image with brightness added\n",
    "    \"\"\"\n",
    "    image = image.astype(\"int16\")\n",
    "    image = image + value\n",
    "    image = ceil_floor_image(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def ceil_floor_image(image):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image : numpy array of image in datatype int16\n",
    "    Return :\n",
    "        image : numpy array of image in datatype uint8 with ceilling(maximum 255) and flooring(minimum 0)\n",
    "    \"\"\"\n",
    "    image[image > 255] = 255\n",
    "    image[image < 0] = 0\n",
    "    image = image.astype(\"uint8\")\n",
    "    return image\n",
    "\n",
    "\n",
    "def approximate_image(image):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image : numpy array of image in datatype int16\n",
    "    Return :\n",
    "        image : numpy array of image in datatype uint8 only with 255 and 0\n",
    "    \"\"\"\n",
    "    image[image > 127.5] = 255\n",
    "    image[image < 127.5] = 0\n",
    "    image = image.astype(\"uint8\")\n",
    "    return image\n",
    "\n",
    "\n",
    "def normalization1(image, mean, std):\n",
    "    \"\"\" Normalization using mean and std\n",
    "    Args :\n",
    "        image : numpy array of image\n",
    "        mean :\n",
    "    Return :\n",
    "        image : numpy array of image with values turned into standard scores\n",
    "    \"\"\"\n",
    "\n",
    "    image = image / 255  # values will lie between 0 and 1.\n",
    "    image = (image - mean) / std\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def normalization2(image, max, min):\n",
    "    \"\"\"Normalization to range of [min, max]\n",
    "    Args :\n",
    "        image : numpy array of image\n",
    "        mean :\n",
    "    Return :\n",
    "        image : numpy array of image with values turned into standard scores\n",
    "    \"\"\"\n",
    "    image_new = (image - np.min(image))*(max - min)/(np.max(image)-np.min(image)) + min\n",
    "    return image_new\n",
    "\n",
    "\n",
    "def stride_size(image_len, crop_num, crop_size):\n",
    "    \"\"\"return stride size\n",
    "    Args :\n",
    "        image_len(int) : length of one size of image (width or height)\n",
    "        crop_num(int) : number of crop in certain direction\n",
    "        crop_size(int) : size of crop\n",
    "    Return :\n",
    "        stride_size(int) : stride size\n",
    "    \"\"\"\n",
    "    return int((image_len - crop_size)/(crop_num - 1))\n",
    "\n",
    "\n",
    "def multi_cropping(image, crop_size, crop_num1, crop_num2):\n",
    "    \"\"\"crop the image and pad it to in_size\n",
    "    Args :\n",
    "        images : numpy arrays of images\n",
    "        crop_size(int) : size of cropped image\n",
    "        crop_num2 (int) : number of crop in horizontal way\n",
    "        crop_num1 (int) : number of crop in vertical way\n",
    "    Return :\n",
    "        cropped_imgs : numpy arrays of stacked images\n",
    "    \"\"\"\n",
    "\n",
    "    img_height, img_width = image.shape[0], image.shape[1]\n",
    "    assert crop_size*crop_num1 >= img_width and crop_size * \\\n",
    "        crop_num2 >= img_height, \"Whole image cannot be sufficiently expressed\"\n",
    "    assert crop_num1 <= img_width - crop_size + 1 and crop_num2 <= img_height - \\\n",
    "        crop_size + 1, \"Too many number of crops\"\n",
    "\n",
    "    cropped_imgs = []\n",
    "    # int((img_height - crop_size)/(crop_num1 - 1))\n",
    "    dim1_stride = stride_size(img_height, crop_num1, crop_size)\n",
    "    # int((img_width - crop_size)/(crop_num2 - 1))\n",
    "    dim2_stride = stride_size(img_width, crop_num2, crop_size)\n",
    "    for i in range(crop_num1):\n",
    "        for j in range(crop_num2):\n",
    "            cropped_imgs.append(cropping(image, crop_size,\n",
    "                                         dim1_stride*i, dim2_stride*j))\n",
    "    return np.asarray(cropped_imgs)\n",
    "\n",
    "\n",
    "# IT IS NOT USED FOR PAD AND CROP DATA OPERATION\n",
    "# IF YOU WANT TO USE CROP AND PAD USE THIS FUNCTION\n",
    "\"\"\"\n",
    "def multi_padding(images, in_size, out_size, mode):\n",
    "    '''Pad the images to in_size\n",
    "    Args :\n",
    "        images : numpy array of images (CxHxW)\n",
    "        in_size(int) : the input_size of model (512)\n",
    "        out_size(int) : the output_size of model (388)\n",
    "        mode(str) : mode of padding\n",
    "    Return :\n",
    "        padded_imgs: numpy arrays of padded images\n",
    "    '''\n",
    "    pad_size = int((in_size - out_size)/2)\n",
    "    padded_imgs = []\n",
    "    for num in range(images.shape[0]):\n",
    "        padded_imgs.append(add_padding(images[num], in_size, out_size, mode=mode))\n",
    "    return np.asarray(padded_imgs)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def cropping(image, crop_size, dim1, dim2):\n",
    "    \"\"\"crop the image and pad it to in_size\n",
    "    Args :\n",
    "        images : numpy array of images\n",
    "        crop_size(int) : size of cropped image\n",
    "        dim1(int) : vertical location of crop\n",
    "        dim2(int) : horizontal location of crop\n",
    "    Return :\n",
    "        cropped_img: numpy array of cropped image\n",
    "    \"\"\"\n",
    "    cropped_img = image[dim1:dim1+crop_size, dim2:dim2+crop_size]\n",
    "    return cropped_img\n",
    "\n",
    "\n",
    "def add_padding(image, in_size, out_size, mode):\n",
    "    \"\"\"Pad the image to in_size\n",
    "    Args :\n",
    "        images : numpy array of images\n",
    "        in_size(int) : the input_size of model\n",
    "        out_size(int) : the output_size of model\n",
    "        mode(str) : mode of padding\n",
    "    Return :\n",
    "        padded_img: numpy array of padded image\n",
    "    \"\"\"\n",
    "    pad_size = int((in_size - out_size)/2)\n",
    "    padded_img = np.pad(image, pad_size, mode=mode)\n",
    "    return padded_img\n",
    "\n",
    "\n",
    "def division_array(crop_size, crop_num1, crop_num2, dim1, dim2):\n",
    "    \"\"\"Make division array\n",
    "    Args :\n",
    "        crop_size(int) : size of cropped image\n",
    "        crop_num2 (int) : number of crop in horizontal way\n",
    "        crop_num1 (int) : number of crop in vertical way\n",
    "        dim1(int) : vertical size of output\n",
    "        dim2(int) : horizontal size_of_output\n",
    "    Return :\n",
    "        div_array : numpy array of numbers of 1,2,4\n",
    "    \"\"\"\n",
    "    div_array = np.zeros([dim1, dim2])  # make division array\n",
    "    one_array = np.ones([crop_size, crop_size])  # one array to be added to div_array\n",
    "    dim1_stride = stride_size(dim1, crop_num1, crop_size)  # vertical stride\n",
    "    dim2_stride = stride_size(dim2, crop_num2, crop_size)  # horizontal stride\n",
    "    for i in range(crop_num1):\n",
    "        for j in range(crop_num2):\n",
    "            # add ones to div_array at specific position\n",
    "            div_array[dim1_stride*i:dim1_stride*i + crop_size,\n",
    "                      dim2_stride*j:dim2_stride*j + crop_size] += one_array\n",
    "    return div_array\n",
    "\n",
    "\n",
    "def image_concatenate(image, crop_num1, crop_num2, dim1, dim2):\n",
    "    \"\"\"concatenate images\n",
    "    Args :\n",
    "        image : output images (should be square)\n",
    "        crop_num2 (int) : number of crop in horizontal way (2)\n",
    "        crop_num1 (int) : number of crop in vertical way (2)\n",
    "        dim1(int) : vertical size of output (512)\n",
    "        dim2(int) : horizontal size_of_output (512)\n",
    "    Return :\n",
    "        div_array : numpy arrays of numbers of 1,2,4\n",
    "    \"\"\"\n",
    "    crop_size = image.shape[1]  # size of crop\n",
    "    empty_array = np.zeros([dim1, dim2]).astype(\"float64\")  # to make sure no overflow\n",
    "    dim1_stride = stride_size(dim1, crop_num1, crop_size)  # vertical stride\n",
    "    dim2_stride = stride_size(dim2, crop_num2, crop_size)  # horizontal stride\n",
    "    index = 0\n",
    "    for i in range(crop_num1):\n",
    "        for j in range(crop_num2):\n",
    "            # add image to empty_array at specific position\n",
    "            empty_array[dim1_stride*i:dim1_stride*i + crop_size,\n",
    "                        dim2_stride*j:dim2_stride*j + crop_size] += image[index]\n",
    "            index += 1\n",
    "    return empty_array\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devswha",
   "language": "python",
   "name": "devswha"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
