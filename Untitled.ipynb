{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The author of paper propose a simple and effective end-to-end image segmentation network architecture for medical images.\n",
    "The proposed network, called U-net, has main three factors for well-training.\n",
    "- U-shaped network structure with two configurations: Contracting and Expanding path\n",
    "- Training more faster than sliding-windows: Patch units and Overlap-tile\n",
    "- Data augmentation: Elastic deformation and Weight cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we used is Transmission Electron Microscopy (ssTEM) data set of the Drosophila first instar larva ventral nerve cord (VNC), which is dowloaded from [ISBI Challenge: Segmentation of of neural structures in EM stacks](http://brainiac2.mit.edu/isbi_challenge/home)\n",
    "\n",
    "\n",
    "![ISBI](./images/ISBI.gif)\n",
    "\n",
    "\n",
    "- Black and white segmentation of membrane and cell with EM(Electron Microscopic) image.\n",
    "- The data set is a large size of image and few so the data augmentation is needed.\n",
    "- The data set contains 30 images of size 512x512 for the train, train-labels and test.\n",
    "- There is no images for test-labels for the ISBI competition.\n",
    "- If you want to get the evaluation metrics of competition, you should split part of the train data set for testing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlap-tile\n",
    "\n",
    "\n",
    "Sliding Window\n",
    "![sliding_window](./images/sliding_window.png) \n",
    "\n",
    "\n",
    "Patch\n",
    "![patch](./images/patch.png) \n",
    "\n",
    "\n",
    "- Patch method has low overlap ratio so that the speed of detection can be improvement.\n",
    "- However, as the wide size of patch detect image at once, the performance of context is good but the performance of localization is lower.\n",
    "- In this paper, the U-net architecture and overlap-tile methods were proposed to solve this localization problem.\n",
    "\n",
    "\n",
    "Overlap-tile\n",
    "![overlap_tile](./images/overlap_tile.png)\n",
    "\n",
    "\n",
    "Simple. Because the EM image is large, sometimes the model of detection input is larger than the patch size (yellow). If so, mirror and fill in the patch area with the empty part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmenation\n",
    "\n",
    "We preprocessed the images for data augmentation. Following preprocessing are :\n",
    "   * Flip\n",
    "   * Gaussian noise\n",
    "   * Uniform noise\n",
    "   * Brightness\n",
    "   * Elastic deformation\n",
    "   * Crop\n",
    "   * Pad \n",
    "   \n",
    "You can easily to understand refer this [page](https://github.com/ugent-korea/pytorch-unet-segmentation/blob/master/README.md#preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Augment train images...\n",
      "------------------------------\n",
      "Using real-time data augmentation. len:  30\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img,array_to_img\n",
    "from utills import *\n",
    "from random import randint\n",
    "from PIL import Image, ImageSequence\n",
    "import os\n",
    "\n",
    "\n",
    "class dataAugment(object):\n",
    "    def __init__(self, out_rows, out_cols, data_path=\"./data\"):\n",
    "        self.out_rows = out_rows\n",
    "        self.out_cols = out_cols\n",
    "        self.data_path = data_path\n",
    "\n",
    "    def augmentation(self):\n",
    "        # read images\n",
    "        print('-' * 30)\n",
    "        print('Augment train images...')\n",
    "        print('-' * 30)\n",
    "\n",
    "        # Create directory\n",
    "        if not os.path.exists(self.data_path + \"/raw/images\"):\n",
    "            os.makedirs(self.data_path + \"/raw/images\")\n",
    "        if not os.path.exists(self.data_path + \"/raw/labels\"):\n",
    "            os.makedirs(self.data_path + \"/raw/labels\")\n",
    "        if not os.path.exists(self.data_path + \"/aug/images\"):\n",
    "            os.makedirs(self.data_path + \"/aug/images\")\n",
    "        if not os.path.exists(self.data_path + \"/aug/labels\"):\n",
    "            os.makedirs(self.data_path + \"/aug/labels\")\n",
    "        if not os.path.exists(self.data_path + \"/npy\"):\n",
    "            os.makedirs(self.data_path + \"/npy\")\n",
    "\n",
    "        # Split isbi tif image&label to single frame of png images\n",
    "        isbi_img = Image.open(self.data_path + \"/train-volume.tif\")  # raw image from isbi dataset\n",
    "        for i, page in enumerate(ImageSequence.Iterator(isbi_img)):\n",
    "            page.save(self.data_path+\"/raw/images/\" + str(i) + \".png\")\n",
    "\n",
    "        isbi_lbl = Image.open(self.data_path + \"/train-labels.tif\")  # raw image from isbi dataset\n",
    "        for i, page in enumerate(ImageSequence.Iterator(isbi_lbl)):\n",
    "            page.save(self.data_path+\"/raw/labels/\" + str(i) + \".png\")\n",
    "\n",
    "        train_imgs = glob.glob(self.data_path + \"/raw/images/*.png\")\n",
    "        label_imgs = glob.glob(self.data_path + \"/raw/labels/*.png\")\n",
    "        slices = len(train_imgs)\n",
    "        if len(train_imgs) != len(label_imgs) or len(train_imgs) == 0:\n",
    "            print(\"trains can't match labels\")\n",
    "            return 0\n",
    "\n",
    "        print('Using real-time data augmentation. len: ', slices)\n",
    "        # one by one augmentation\n",
    "        batch_size = 30  # one frame for 30 images augment\n",
    "        for i in range(slices):\n",
    "            for b in range(batch_size):\n",
    "                img_as_img = Image.open(self.data_path + \"/raw/images/\" + str(i) + \".png\")\n",
    "                lbl_as_img = Image.open(self.data_path + \"/raw/labels/\" + str(i) + \".png\")\n",
    "                img_as_np = np.asarray(img_as_img)\n",
    "                lbl_as_np = np.asarray(lbl_as_img)\n",
    "\n",
    "                # flip {0: vertical, 1: horizontal, 2: both, 3: none}\n",
    "                flip_num = randint(0, 3)\n",
    "                img_as_np = flip(img_as_np, flip_num)\n",
    "                lbl_as_np = flip(lbl_as_np, flip_num)\n",
    "\n",
    "                # Noise Determine {0: Gaussian_noise, 1: uniform_noise\n",
    "                if randint(0, 1):\n",
    "                    # Gaussian_noise\n",
    "                    gaus_sd, gaus_mean = randint(0, 20), 0\n",
    "                    img_as_np = add_gaussian_noise(img_as_np, gaus_mean, gaus_sd)\n",
    "                    lbl_as_np = add_gaussian_noise(lbl_as_np, gaus_mean, gaus_sd)\n",
    "                else:\n",
    "                    # uniform_noise\n",
    "                    l_bound, u_bound = randint(-20, 0), randint(0, 20)\n",
    "                    img_as_np = add_uniform_noise(img_as_np, l_bound, u_bound)\n",
    "                    lbl_as_np = add_uniform_noise(lbl_as_np, l_bound, u_bound)\n",
    "\n",
    "                # Brightness\n",
    "                pix_add = randint(-20, 20)\n",
    "                img_as_np = change_brightness(img_as_np, pix_add)\n",
    "                lbl_as_np = change_brightness(lbl_as_np, pix_add)\n",
    "\n",
    "                # Elastic distort {0: distort, 1:no distort}\n",
    "                sigma = randint(6, 12)\n",
    "                # sigma = 4, alpha = 34\n",
    "                img_as_np, seed = add_elastic_transform(img_as_np, alpha=34, sigma=sigma, pad_size=20)\n",
    "                lbl_as_np, seed = add_elastic_transform(lbl_as_np, alpha=34, sigma=sigma, pad_size=20)\n",
    "\n",
    "                # Crop the image\n",
    "                in_size = 512\n",
    "                out_size = 388\n",
    "                img_height, img_width = img_as_np.shape[0], img_as_np.shape[1]\n",
    "                pad_size = int((in_size - out_size)/2)\n",
    "                img_as_np = np.pad(img_as_np, pad_size, mode=\"symmetric\")\n",
    "                lbl_as_np = np.pad(lbl_as_np, pad_size, mode=\"symmetric\")\n",
    "                y_loc, x_loc = randint(0, img_height-out_size), randint(0, img_width-out_size)\n",
    "                img_as_np = cropping(img_as_np, crop_size=in_size, dim1=y_loc, dim2=x_loc)\n",
    "                lbl_as_np = cropping(lbl_as_np, crop_size=in_size, dim1=y_loc, dim2=x_loc)\n",
    "\n",
    "                # Normalize the image\n",
    "                img_as_np = normalization2(img_as_np, max=1, min=0)\n",
    "                img = img_as_np.reshape(img_as_np.shape[0], img_as_np.shape[1], 1)\n",
    "                img = array_to_img(img)\n",
    "                img.save(self.data_path + \"/aug/images/\" + str(30*i+b) + \".png\")\n",
    "\n",
    "                lbl = lbl_as_np.reshape(lbl_as_np.shape[0], lbl_as_np.shape[1], 1)\n",
    "                lbl = array_to_img(lbl)\n",
    "                lbl.save(self.data_path + \"/aug/labels/\" + str(30*i+b) + \".png\")\n",
    "\n",
    "            print(str(i+1))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        mydata = dataAugment(512, 512)\n",
    "        mydata.augmentation()\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data pre-process for converting .tif to .png\n",
    "\n",
    "Create the train, train-label, test png image files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Creating training images...\n",
      "------------------------------\n",
      "original images 0\n",
      "augmented images 0\n",
      "loading done\n",
      "Saving to .npy files done.\n",
      "------------------------------\n",
      "Creating test images...\n",
      "------------------------------\n",
      "loading done\n",
      "Saving to imgs_test.npy files done.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import img_to_array, load_img,array_to_img\n",
    "import numpy as np \n",
    "import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "class dataProcess(object):\n",
    "    def __init__(self, out_rows, out_cols, data_path = \"./data\", img_type = \"tif\"):\n",
    "        self.out_rows = out_rows\n",
    "        self.out_cols = out_cols\n",
    "        self.data_path = data_path\n",
    "        self.img_type = img_type\n",
    "    \n",
    "    # Image to numpy \n",
    "    def create_train_data(self):\n",
    "        i = 0\n",
    "        j = 0\n",
    "        print('-'*30)\n",
    "        print('Creating training images...')\n",
    "        print('-'*30)\n",
    "        imgs = glob.glob(self.data_path+\"/raw/train/*.\"+self.img_type)\n",
    "        augimgs = glob.glob(self.data_path+\"/aug/train/*.\"+self.img_type)\n",
    "        print(\"original images\",len(imgs))\n",
    "        print(\"augmented images\",len(augimgs))\n",
    "        imgdatas = np.ndarray((len(imgs)+len(augimgs),self.out_rows,self.out_cols,1), dtype=np.uint8)\n",
    "        imglabels = np.ndarray((len(imgs)+len(augimgs),self.out_rows,self.out_cols,1), dtype=np.uint8)\n",
    "        for imgname in imgs:\n",
    "            midname = imgname[imgname.rindex(\"/\")+1:]\n",
    "            img = load_img(self.data_path + \"/raw/train/\" + midname,color_mode = \"grayscale\")\n",
    "            label = load_img(self.data_path + \"/raw/label/\" + midname,color_mode = \"grayscale\")\n",
    "            img = img_to_array(img)\n",
    "            label = img_to_array(label)\n",
    "            imgdatas[i] = img\n",
    "            imglabels[i] = label\n",
    "            j += 1\n",
    "            if j % 30 == 0:\n",
    "                print('Done: {0}/{1} images'.format(j, len(imgs)))\n",
    "        for imgname in augimgs:\n",
    "            midname = imgname[imgname.rindex(\"/\")+1:]\n",
    "            img = load_img(self.data_path + \"/aug/train/\" + midname,color_mode = \"grayscale\")\n",
    "            label = load_img(self.data_path + \"/aug/label/\" + midname,color_mode = \"grayscale\")\n",
    "            img = img_to_array(img)\n",
    "            label = img_to_array(label)\n",
    "            imgdatas[i] = img\n",
    "            imglabels[i] = label\n",
    "            i += 1\n",
    "            if i % 100 == 0:\n",
    "                print('Done: {0}/{1} images'.format(i, len(augimgs)))\n",
    "    \n",
    "        print('loading done')\n",
    "        np.save(self.data_path + '/npy/imgs_train.npy', imgdatas)\n",
    "        np.save(self.data_path + '/npy/imgs_mask_train.npy', imglabels)\n",
    "        print('Saving to .npy files done.')\n",
    "    \n",
    "    def create_test_data(self):\n",
    "        print('-'*30)\n",
    "        print('Creating test images...')\n",
    "        print('-'*30)\n",
    "        imgs = glob.glob(self.data_path+\"/raw/test/*.\"+self.img_type)\n",
    "        imgdatas = np.ndarray((len(imgs),self.out_rows,self.out_cols,1), dtype=np.uint8)\n",
    "        for ind in range(len(imgs)):\n",
    "            img = load_img(self.data_path + \"/raw/test/\" +str(ind)+\".tif\",color_mode = \"grayscale\")\n",
    "            img = img_to_array(img)\n",
    "            imgdatas[ind] = img\n",
    "            ind += 1\n",
    "        print('loading done')\n",
    "        np.save(self.data_path + '/npy/imgs_test.npy', imgdatas)\n",
    "        print('Saving to imgs_test.npy files done.')\n",
    "    \n",
    "    \n",
    "    # Masking and Labeling for training\n",
    "    def load_train_data(self):\n",
    "        print('-'*30)\n",
    "        print('load train images...')\n",
    "        print('-'*30)\n",
    "        imgs_train = np.load(self.data_path+\"/npy/imgs_train.npy\")\n",
    "        imgs_mask_train = np.load(self.data_path+\"/npy/imgs_mask_train.npy\")\n",
    "        imgs_train = imgs_train.astype('float32')\n",
    "        imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "        print(imgs_train)\n",
    "        imgs_train /= 255 # RGB 0~1\n",
    "        imgs_mask_train /= 255\n",
    "        imgs_mask_train[imgs_mask_train > 0.5] = 1 # Membrane\n",
    "        imgs_mask_train[imgs_mask_train <= 0.5] = 0 # Cell\n",
    "        return imgs_train,imgs_mask_train\n",
    "    \n",
    "    def load_test_data(self):\n",
    "        print('-'*30)\n",
    "        print('load test images...')\n",
    "        print('-'*30)\n",
    "        imgs_test = np.load(self.data_path+\"/npy/imgs_test.npy\")\n",
    "        imgs_test = imgs_test.astype('float32')\n",
    "        imgs_test /= 255\n",
    "        return imgs_test\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        with tf.device('/device:GPU:1'):\n",
    "            mydata = dataProcess(512,512)\n",
    "            mydata.create_train_data()\n",
    "            mydata.create_test_data()\n",
    "    except RuntimeError as e:\n",
    "      print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Unet](./images/unet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Contracting Path(Fully Convolution)\n",
    "- 전형적인 convolution network. \n",
    "- 3x3 conv 와 max-pooling, drop out\n",
    "- 이미지 feature 을 정확하게 추출하나 feature map 크기가 줄어듬\n",
    "\n",
    "\n",
    "### Expanding Path(Deconvolution)\n",
    "- 줄어든 feature map 의 크기를 다시 복구하여 ouput segmentation map 출력\n",
    "- 2x2 up-conv 와 3x3 conv, concatenate\n",
    "- expand 과정은 localization에 대한 정보를 잃게 된다는 단점\n",
    "- 따라서, up-conv 된 이후의 feature map 과 동일한 level 의 feature map 을 결합하여 localization 정보를 제공\n",
    "- 마지막은 1x1 conv mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def unet(pretrained_weights = None,input_size = (512,512,1)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4) # for crop and copy\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3) # Concatenate for localization informantion\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    #model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "from model import unet\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tifffile import imsave as tifsave\n",
    "\n",
    "\n",
    "class myUnet(object):\n",
    "\n",
    "    def __init__(self, img_rows=512, img_cols=512, save_path=\"./results/\"):\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def load_data(self):\n",
    "        mydata = dataProcess(self.img_rows, self.img_cols)\n",
    "        imgs_train, imgs_mask_train = mydata.load_train_data()\n",
    "        imgs_test = mydata.load_test_data()\n",
    "        print(imgs_test)\n",
    "        return imgs_train, imgs_mask_train, imgs_test\n",
    "\n",
    "    def train(self, load_pretrained):\n",
    "        print(\"loading data\")\n",
    "        model_name = 'my_model.h5'\n",
    "        log_dir = \"logs/000\"\n",
    "        logging = TensorBoard(log_dir=log_dir)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
    "        imgs_train, imgs_mask_train, imgs_test = self.load_data()\n",
    "        print(\"loading data done\")\n",
    "        if load_pretrained:\n",
    "            model = load_model(model_name)\n",
    "            model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "            model_checkpoint = ModelCheckpoint('unet.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "            model.fit(imgs_train, imgs_mask_train, batch_size=2, epochs=30, verbose=1,\n",
    "                      validation_split=0.2, shuffle=True, callbacks=[logging, model_checkpoint, reduce_lr])\n",
    "            model.save(model_name)\n",
    "        else:\n",
    "            model = unet()\n",
    "            model.summary()\n",
    "            model_checkpoint = ModelCheckpoint('unet.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "            model.fit(imgs_train, imgs_mask_train, batch_size=2, epochs=30, verbose=1,\n",
    "                      validation_split=0.2, shuffle=True,\n",
    "                      callbacks=[logging, model_checkpoint, reduce_lr, early_stopping])\n",
    "            model.save(model_name)\n",
    "\n",
    "    def test(self):\n",
    "        model_name = 'my_model.h5'\n",
    "        if not os.path.exists(self.save_path):\n",
    "            os.makedirs(self.save_path)\n",
    "\n",
    "        imgs_train, imgs_mask_train, imgs_test = self.load_data()\n",
    "        model = load_model(model_name)\n",
    "        imgs_mask_test = model.predict(imgs_test, batch_size=2, verbose=1)\n",
    "        np.save(self.save_path + \"imgs_mask_test.npy\", imgs_mask_test)\n",
    "\n",
    "        print(\"array to image\")\n",
    "        imgs = np.load(self.save_path + \"imgs_mask_test.npy\")\n",
    "        total = []\n",
    "        for i in range(imgs.shape[0]):\n",
    "            img = imgs[i]\n",
    "            img[img > 0.5] = 1\n",
    "            img[img <= 0.5] = 0\n",
    "            total.append(img)\n",
    "        np_total = np.array(total)\n",
    "        tifsave(\"./prediction.tif\", np_total)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    myunet = myUnet()\n",
    "    myunet.train(load_pretrained=False)\n",
    "    myunet.test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Result\n",
    "\n",
    "![test-volume](./images/test-volume.tif) ![test](./images/total_result_aug_10.tif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devswha",
   "language": "python",
   "name": "devswha"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}